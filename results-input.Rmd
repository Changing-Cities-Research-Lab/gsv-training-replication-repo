---
title: "Results"
author: "XXX"
date: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r summary}
# Script Description ------------------------------------------------------

# Use this script to generate the tables that are in the training data paper.

# Inputs:
# Pairwise data - pairs.csv
# Single Image dataset - single_image.csv

```


```{r packages}

# Libraries and Directories
rm(list=ls())
library("gtools")
library("tidyverse")
library("readr")
library("irr") #for agreement, reliability

#SET WORKING DIRECTORY HERE

```

# Load Data and Set Appropriate Column Types
```{r data}

setwd("/Users/nimadahir/Library/CloudStorage/GoogleDrive-ndahir@stanford.edu/.shortcut-targets-by-id/0B3mRackNzIMhYVAweUc2ZmxFVk0/PROJECT FOLDER: GSV/background and drafts/Drafts/reliability/replication-data")

single_image <- read_csv("single_image.csv",
                         guess_max = 1000000) # read_csv will use the first 1,000 rows to guess type, but since this is missing for a lot of columns, they are incorrectly called in as logical. So, we want to maximize the number of guesses. This will slow down read_csv, but necessary for import.


pairs <- read_csv("pairs.csv",
                  guess_max = 1000000)

```

# Tables

## Table 1: Number of Unique Images Coded by MTurkers

```{r images-mturkers}
single_results <- single_image %>% 
  filter(!is.na(single_mturk_rating1)) %>% # Keep only those that have at least 1 MTurk rating
  group_by(city) %>% 
  summarize(
    single_image_coders = mean(unique_mturkers,na.rm=TRUE), # Calculate the number of unique MTurk coders 
    single_images_coded = n_distinct(image_name) # Calculate the number of unique images coded
  )

pairs_results <- pairs %>% 
  filter(!is.na(pairs_mturk_choice1)) %>% # Keep only those that have at least 1 MTurk rating
  mutate(ID = group_indices(.,image_name1,image_name2)) %>% # Create group idetnifier for each pair - based on image 1 and image 2
  group_by(city) %>% 
  filter(!grepl("_MA_",image_name1)) %>% #remove earlier pairwise Boston results, irrelevant for analysis here.
  summarize(
    pairs_coders = mean(unique_mturkers,na.rm=TRUE), # Calculate the number of unique MTurk coders 
    pairs_coded = n_distinct(ID)  # Calculate the number of unique images coded
  ) %>% 
  dplyr::select(-city)

cbind(single_results,pairs_results) # Put together for table

rm(single_results,pairs_results)
```

## Table 2 : Distribution of Trash in Training Data

```{r training-data}

single_image %>% 
  filter(training==1) %>% # Keep only those in the training set
  group_by(city,trueskill_rating) %>% # Group by city and each category
  summarize(n = n()) %>% # Count by category/city
  mutate(percent = n/sum(n)*100) # Calculate percentage in each category


```

## Table 3 : Distribution of ML Predictions of Trash
```{r ml-distributions}

single_image %>%
  filter(!is.na(pred_svm)) %>% 
  group_by(city) %>%
  summarize(pred_0 = sum(pred_svm==0, na.rm = T), pred_1 = sum(pred_svm==1, na.rm = T), total = n()) %>%
  mutate(perc = pred_1/total)


```

## Table 4 : Counts of Images from Coding Sessions
```{r images-coders}
single_results <- single_image %>% 
  filter(!is.na(single_cs_rating1)) %>% 
  group_by(city) %>% 
  summarize(
    single_image_coders = mean(unique_coders,na.rm=TRUE),
    single_images_coded = n_distinct(image_name)
  )

pairs_results <- pairs %>% 
  filter(!is.na(pairs_cs_choice1)) %>% 
  mutate(ID = group_indices(.,image_name1,image_name2)) %>% 
  group_by(city) %>% 
  summarize(
    pairs_coders = mean(unique_coders,na.rm=TRUE),
    pairs_coded = n_distinct(ID)
  ) %>% 
  dplyr::select(-city)

cbind(single_results,pairs_results)

rm(single_results,pairs_results)
```

## Table 5 : Pair Comparisons Reliability Panel 1
```{r pairwise-reliability-betweenraters}
# Data----
#Create separate dataframes for each city
bos <- pairs %>% 
  dplyr::select(city,starts_with("pairs_cs_choice")) %>% # Keep only the coding sessions results here
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(where(is.numeric))))) %>% # Sum across all numeric columns to get the number of columns
  filter(n_raters > 1 & city=="Boston") # For reliability measures, we want only those that have more than 1 rater.

det <- pairs %>% 
  dplyr::select(city,starts_with("pairs_cs_choice")) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(where(is.numeric))))) %>% 
  filter(n_raters > 1 & city=="Detroit") 

la <- pairs %>% 
  dplyr::select(city,starts_with("pairs_cs_choice")) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(where(is.numeric))))) %>% 
  filter(n_raters > 1 & city=="LA") 

#Boston----
#Only two raters in Boston
agree(bos[(bos$n_raters==2), c(2:3)]) # For those with only 2 raters, calculate agreement between their ratings
icc(bos[(bos$n_raters==2), c(2:3)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==2), c(2:3)])), "ordinal")

#Detroit----
#Two raters
agree(det[(det$n_raters==2), c(2:3)]) 
icc(det[(det$n_raters==2), c(2:3)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==2), c(2:3)])), "ordinal")

#Three raters
agree(det[(det$n_raters==3), c(2:4)]) 
icc(det[(det$n_raters==3), c(2:4)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==3), c(2:4)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(det[(det$n_raters==2), c(2:3)])$value * agree(det[(det$n_raters==2), c(2:3)])$subjects) + 
    (agree(det[(det$n_raters==3), c(2:4)])$value * agree(det[(det$n_raters==3), c(2:4)])$subjects))/
  (agree(det[(det$n_raters==2), c(2:3)])$subjects + agree(det[(det$n_raters==3), c(2:4)])$subjects)

#LA----
agree(la[(la$n_raters==2), c(2:3)]) 
icc(la[(la$n_raters==2), c(2:3)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==2), c(2:3)])), "ordinal")

#Three raters
agree(la[(la$n_raters==3), c(2:4)]) 
icc(la[(la$n_raters==3), c(2:4)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==3), c(2:4)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(la[(la$n_raters==2), c(2:3)])$value * agree(la[(la$n_raters==2), c(2:3)])$subjects) + 
  (agree(la[(la$n_raters==3), c(2:4)])$value * agree(la[(la$n_raters==3), c(2:4)])$subjects))/
  (agree(la[(la$n_raters==2), c(2:3)])$subjects + agree(la[(la$n_raters==3), c(2:4)])$subjects)

rm(bos,det,la) #Clean up environment
```

### Table 5 : Pair Comparisons Reliability Panel 1

```{r pairwise-reliability-betweenratersandmturk}

# Data----
#Look only at those that all agree in coding sessions
#Create separate dataframes for each city:
bos <- pairs %>% 
  dplyr::select(city,starts_with("pairs_cs_choice"),starts_with("pairs_mturk_choice")) %>% # Keep Mturk and coding sessions pair comparison results
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(starts_with("pairs_cs_choice"))))) %>% # Calculate the number of raters from the coding sessions
  mutate(var = var(c_across(starts_with("pairs_cs_choice")), na.rm = TRUE)) %>% # Calculate variance across the pairwise coding session results
  filter(var==0 | (is.na(var) & !is.na(pairs_cs_choice1))) %>% #Keep those with no variance (i.e. equal) or NA variance (i.e. one rater)
  filter(city=="Boston")

det <- pairs %>% 
  dplyr::select(city,starts_with("pairs_cs_choice"),starts_with("pairs_mturk_choice")) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(starts_with("pairs_cs_choice"))))) %>% 
  mutate(var = var(c_across(starts_with("pairs_cs_choice")), na.rm = TRUE)) %>% 
  filter(var==0 | (is.na(var) & !is.na(pairs_cs_choice1))) %>% #Keep those with no variance (i.e. equal) or NA variance (i.e. one rater)
  filter(city=="Detroit")

la <- pairs %>% 
  dplyr::select(city,starts_with("pairs_cs_choice"),starts_with("pairs_mturk_choice")) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(starts_with("pairs_cs_choice"))))) %>% 
  mutate(var = var(c_across(starts_with("pairs_cs_choice")), na.rm = TRUE)) %>% 
  filter(var==0 | (is.na(var) & !is.na(pairs_cs_choice1))) %>% #Keep those with no variance (i.e. equal) or NA variance (i.e. one rater)
  filter(city=="LA")

# Boston----
#One Rater
agree(bos[(bos$n_raters==1), c(2,6)]) 
icc(bos[(bos$n_raters==1), c(2,6)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==1), c(2,6)])), "ordinal")

#Two Raters
agree(bos[(bos$n_raters==2), c(2:3,6)]) 
icc(bos[(bos$n_raters==2), c(2:3,6)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==2), c(2:3,6)])), "ordinal")
#Overall - calculated weighted average of agreement
((agree(bos[(bos$n_raters==1), c(2,6)])$value * agree(bos[(bos$n_raters==1), c(2,6)])$subjects) + 
  (agree(bos[(bos$n_raters==2), c(2:3,6)])$value * agree(bos[(bos$n_raters==2), c(2:3,6)])$subjects))/
  (agree(bos[(bos$n_raters==1), c(2,6)])$subjects + agree(bos[(bos$n_raters==2), c(2:3,6)])$subjects)

#Detroit----
#One Rater
agree(det[(det$n_raters==1), c(2,6)]) 
icc(det[(det$n_raters==1), c(2,6)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==1), c(2,6)])), "ordinal")

#Two Raters
agree(det[(det$n_raters==2), c(2:3,6)]) 
icc(det[(det$n_raters==2), c(2:3,6)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==2), c(2:3,6)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(det[(det$n_raters==1), c(2,6)])$value * agree(det[(det$n_raters==1), c(2,6)])$subjects) + 
  (agree(det[(det$n_raters==2), c(2:3,6)])$value * agree(det[(det$n_raters==2), c(2:3,6)])$subjects))/
  (agree(det[(det$n_raters==1), c(2,6)])$subjects + agree(det[(det$n_raters==2), c(2:3,6)])$subjects)

#LA----
#One Rater
agree(la[(la$n_raters==1), c(2,6)]) 
icc(la[(la$n_raters==1), c(2,6)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==1), c(2,6)])), "ordinal")

#Two Raters
agree(la[(la$n_raters==2), c(2:3,6)]) 
icc(la[(la$n_raters==2), c(2:3,6)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==2), c(2:3,6)])), "ordinal")

#Three Raters
agree(la[(la$n_raters==3), c(2:4,6)]) 
icc(la[(la$n_raters==3), c(2:4,6)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==3), c(2:4,6)])), "ordinal")

#Overall - calculated weighted average of agreement:
#Multiply each agree value by the number of subjects in that category and divide by total

((agree(la[(la$n_raters==1), c(2,6)])$value * agree(la[(la$n_raters==1), c(2,6)])$subjects) + 
  (agree(la[(la$n_raters==2), c(2:3,6)])$value * agree(la[(la$n_raters==2), c(2:3,6)])$subjects) +
  agree(la[(la$n_raters==3), c(2:4,6)])$value * agree(la[(la$n_raters==3), c(2:4,6)])$subjects
  )/
  (agree(la[(la$n_raters==1), c(2,6)])$subjects + agree(la[(la$n_raters==2), c(2:3,6)])$subjects
   + agree(la[(la$n_raters==3), c(2:4,6)])$subjects)

```

## Table 6 : Single Image Reliability Panel 1
```{r single-reliability-betweenraters, warning=FALSE}

# Data----
#Create dataframe where at least one single image rating exists
single_image_cs <- single_image %>% 
  filter_at(vars(starts_with("single_cs_rating")),any_vars(!is.na(.)))

#Create separate dataframes for each city
bos <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating")) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(where(is.numeric))))) %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters)) %>% # Grouping raters that are 4+ together
  filter(n_raters > 1 & city=="Boston") 

det <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating")) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(where(is.numeric))))) %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters)) %>% # Grouping raters that are 4+ together
  filter(n_raters > 1 & city=="Detroit")

la <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating")) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(where(is.numeric))))) %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters)) %>% # Grouping raters that are 4+ together
  filter(n_raters > 1 & city=="LA")

#Boston----
#Two Raters
agree(bos[(bos$n_raters==2), c(2:3)]) 
icc(bos[(bos$n_raters==2), c(2:3)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==2), c(2:3)])), "ordinal")

#Three Raters
agree(bos[(bos$n_raters==3), c(2:4)]) 
icc(bos[(bos$n_raters==3), c(2:4)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==3), c(2:4)])), "ordinal")

#Four Raters
agree(bos[(bos$n_raters==4), c(2:5)]) 
icc(bos[(bos$n_raters==4), c(2:5)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==4), c(2:5)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(bos[(bos$n_raters==2), c(2:3)])$value * agree(bos[(bos$n_raters==2), c(2:3)])$subjects) +
  agree(bos[(bos$n_raters==3), c(2:4)])$value * agree(bos[(bos$n_raters==3), c(2:4)])$subjects +
  agree(bos[(bos$n_raters==4), c(2:5)])$value * agree(bos[(bos$n_raters==4), c(2:5)])$subjects 
  )/
  (agree(bos[(bos$n_raters==2), c(2:3)])$subjects
   + agree(bos[(bos$n_raters==3), c(2:4)])$subjects +
     agree(bos[(bos$n_raters==4), c(2:5)])$subjects 
   )

#Detroit----
#Two raters
agree(det[(det$n_raters==2), c(2:3)]) 
icc(det[(det$n_raters==2), c(2:3)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==2), c(2:3)])), "ordinal")

#Three raters
agree(det[(det$n_raters==3), c(2:4)]) 
icc(det[(det$n_raters==3), c(2:4)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==3), c(2:4)])), "ordinal")

#Four Raters
agree(det[(det$n_raters==4), c(2:5)]) 
icc(det[(det$n_raters==4), c(2:5)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==4), c(2:5)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(det[(det$n_raters==2), c(2:3)])$value * agree(det[(det$n_raters==2), c(2:3)])$subjects) +
  agree(det[(det$n_raters==3), c(2:4)])$value * agree(det[(det$n_raters==3), c(2:4)])$subjects +
  agree(det[(det$n_raters==4), c(2:5)])$value * agree(det[(det$n_raters==4), c(2:5)])$subjects 
  )/
  (agree(det[(det$n_raters==2), c(2:3)])$subjects
   + agree(det[(det$n_raters==3), c(2:4)])$subjects +
     agree(det[(det$n_raters==4), c(2:5)])$subjects 
   )

#LA----
agree(la[(la$n_raters==2), c(2:3)]) 
icc(la[(la$n_raters==2), c(2:3)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==2), c(2:3)])), "ordinal")

#Three raters
agree(la[(la$n_raters==3), c(2:4)]) 
icc(la[(la$n_raters==3), c(2:4)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==3), c(2:4)])), "ordinal")

#Four raters
agree(la[(la$n_raters==4), c(2:5)]) 
icc(la[(la$n_raters==4), c(2:5)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==4), c(2:5)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(la[(la$n_raters==2), c(2:3)])$value * agree(la[(la$n_raters==2), c(2:3)])$subjects) +
  agree(la[(la$n_raters==3), c(2:4)])$value * agree(la[(la$n_raters==3), c(2:4)])$subjects +
  agree(la[(la$n_raters==4), c(2:5)])$value * agree(la[(la$n_raters==4), c(2:5)])$subjects 
)/
  (agree(la[(la$n_raters==2), c(2:3)])$subjects
   + agree(la[(la$n_raters==3), c(2:4)])$subjects +
     agree(la[(la$n_raters==4), c(2:5)])$subjects 
  )

rm(bos,det,la) #Clean up environment
```

### Table 6: Single Image Reliability Panel 2

```{r single-reliability-betweenratersandmturk}
#Look only at those that all agree in coding sessions

# Create separate dataframes for each city:
bos <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating"),trueskill_rating) %>% 
  filter(!is.na(trueskill_rating)) %>% # Keep only those with Trueskill rating
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(starts_with("single_cs_rating"))))) %>% 
  mutate(var = var(c_across(starts_with("single_cs_rating")), na.rm = TRUE)) %>% 
  filter(var==0 | (is.na(var) & !is.na(single_cs_rating1))) %>% #Keep those with no variance (i.e. equal) or NA variance (i.e. one rater)
  filter(city=="Boston") 

det <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating"),trueskill_rating) %>% 
  filter(!is.na(trueskill_rating)) %>% # Keep only those with Trueskill rating 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(starts_with("single_cs_rating"))))) %>% 
  mutate(var = var(c_across(starts_with("single_cs_rating")), na.rm = TRUE)) %>% 
  filter(var==0 | (is.na(var) & !is.na(single_cs_rating1))) %>% #Keep those with no variance (i.e. equal) or NA variance (i.e. one rater)
  filter(city=="Detroit") %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters))

la <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating"),trueskill_rating) %>% 
  filter(!is.na(trueskill_rating)) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(starts_with("single_cs_rating"))))) %>% 
  mutate(var = var(c_across(starts_with("single_cs_rating")), na.rm = TRUE)) %>% 
  filter(var==0 | (is.na(var) & !is.na(single_cs_rating1))) %>% #Keep those with no variance (i.e. equal) or NA variance (i.e. one rater)
  filter(city=="LA") %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters))  # If more than 4 raters, keep with 4 raters

# Boston----
#Two raters
agree(bos[(bos$n_raters==2), c(2:3,9)]) 
icc(bos[(bos$n_raters==2), c(2:3,9)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==2), c(2:3,9)])), "ordinal")

#Three raters
agree(bos[(bos$n_raters==3), c(2:4,9)]) 
icc(bos[(bos$n_raters==3), c(2:4,9)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==3), c(2:4,9)])), "ordinal")

#Four raters
agree(bos[(bos$n_raters==4), c(2:5,9)]) 
icc(bos[(bos$n_raters==4), c(2:5,9)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==4), c(2:5,9)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(bos[(bos$n_raters==2), c(2:3,9)])$value * agree(bos[(bos$n_raters==2), c(2:3,9)])$subjects) +
  agree(bos[(bos$n_raters==3), c(2:4,9)])$value * agree(bos[(bos$n_raters==3), c(2:4,9)])$subjects +
  agree(bos[(bos$n_raters==4), c(2:5,9)])$value * agree(bos[(bos$n_raters==4), c(2:5,9)])$subjects 
  )/
  (agree(bos[(bos$n_raters==2), c(2:3,9)])$subjects
   + agree(bos[(bos$n_raters==3), c(2:4,9)])$subjects +
     agree(bos[(bos$n_raters==4), c(2:5,9)])$subjects 
   )


#Detroit----
#Two raters
agree(det[(det$n_raters==2), c(2:3,9)]) 
icc(det[(det$n_raters==2), c(2:3,9)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==2), c(2:3,9)])), "ordinal")

#Three raters
agree(det[(det$n_raters==3), c(2:4,9)]) 
icc(det[(det$n_raters==3), c(2:4,9)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==3), c(2:4,9)])), "ordinal")

#Four raters
agree(det[(det$n_raters==4), c(2:5,9)]) 
icc(det[(det$n_raters==4), c(2:5,9)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==4), c(2:5,9)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(det[(det$n_raters==2), c(2:3,9)])$value * agree(det[(det$n_raters==2), c(2:3,9)])$subjects) +
  agree(det[(det$n_raters==3), c(2:4,9)])$value * agree(det[(det$n_raters==3), c(2:4,9)])$subjects +
  agree(det[(det$n_raters==4), c(2:5,9)])$value * agree(det[(det$n_raters==4), c(2:5,9)])$subjects 
)/
  (agree(det[(det$n_raters==2), c(2:3,9)])$subjects
   + agree(det[(det$n_raters==3), c(2:4,9)])$subjects +
     agree(det[(det$n_raters==4), c(2:5,9)])$subjects 
  )

#LA----
#Two raters
agree(la[(la$n_raters==2), c(2:3,9)]) 
icc(la[(la$n_raters==2), c(2:3,9)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==2), c(2:3,9)])), "ordinal")

#Three raters
agree(la[(la$n_raters==3), c(2:4,9)]) 
icc(la[(la$n_raters==3), c(2:4,9)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==3), c(2:4,9)])), "ordinal")

#Four raters
agree(la[(la$n_raters==4), c(2:5,9)]) 
icc(la[(la$n_raters==4), c(2:5,9)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==4), c(2:5,9)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(la[(la$n_raters==2), c(2:3,9)])$value * agree(la[(la$n_raters==2), c(2:3,9)])$subjects) +
  agree(la[(la$n_raters==3), c(2:4,9)])$value * agree(la[(la$n_raters==3), c(2:4,9)])$subjects +
  agree(la[(la$n_raters==4), c(2:5,9)])$value * agree(la[(la$n_raters==4), c(2:5,9)])$subjects 
)/
  (agree(la[(la$n_raters==2), c(2:3,9)])$subjects
   + agree(la[(la$n_raters==3), c(2:4,9)])$subjects +
     agree(la[(la$n_raters==4), c(2:5,9)])$subjects 
  )
```

## Table 7 : Reliability Between Raters and Predictions Panel 1
```{r single-reliability-betweenraters}

#Create dataframe where at least one single image rating exists and create binary version of rating
single_image_cs <- single_image %>% 
  filter_at(vars(starts_with("single_cs_rating")),any_vars(!is.na(.))) %>% # Keep only those that have at least one coding session rating
  mutate(across(starts_with("single_cs_rating"), # Make coding session results binary
                ~ case_when(
                    . %in% c(1) ~ 0, # If a coder rated something as no trash - similar to prediction of 0
                    . %in% c(2,3,4) ~ 1, # Any level of trash - similar to prediction of 1
                    TRUE ~ NA_real_ # Otherwise (rater marked as too obstructed) - this should be NA
                  )
               ))


#Create separate dataframes for each city
bos <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating")) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(where(is.numeric))))) %>% 
  filter(n_raters > 1 & city=="Boston") %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters)) 

det <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating")) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(where(is.numeric))))) %>% 
  filter(n_raters > 1 & city=="Detroit") %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters)) 

la <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating")) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(where(is.numeric))))) %>% 
  filter(n_raters > 1 & city=="LA") %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters))

#Boston----
#Two Raters
agree(bos[(bos$n_raters==2), c(2:3)]) 
icc(bos[(bos$n_raters==2), c(2:3)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==2), c(2:3)])), "ordinal")

#Three Raters
agree(bos[(bos$n_raters==3), c(2:4)]) 
icc(bos[(bos$n_raters==3), c(2:4)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==3), c(2:4)])), "ordinal")

#Four Raters
agree(bos[(bos$n_raters==4), c(2:5)]) 
icc(bos[(bos$n_raters==4), c(2:5)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==4), c(2:5)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(bos[(bos$n_raters==2), c(2:3)])$value * agree(bos[(bos$n_raters==2), c(2:3)])$subjects) +
  agree(bos[(bos$n_raters==3), c(2:4)])$value * agree(bos[(bos$n_raters==3), c(2:4)])$subjects +
  agree(bos[(bos$n_raters==4), c(2:5)])$value * agree(bos[(bos$n_raters==4), c(2:5)])$subjects 
  )/
  (agree(bos[(bos$n_raters==2), c(2:3)])$subjects
   + agree(bos[(bos$n_raters==3), c(2:4)])$subjects +
     agree(bos[(bos$n_raters==4), c(2:5)])$subjects 
   )

#Detroit----
#Two raters
agree(det[(det$n_raters==2), c(2:3)]) 
icc(det[(det$n_raters==2), c(2:3)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==2), c(2:3)])), "ordinal")

#Three raters
agree(det[(det$n_raters==3), c(2:4)]) 
icc(det[(det$n_raters==3), c(2:4)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==3), c(2:4)])), "ordinal")

#Four Raters
agree(det[(det$n_raters==4), c(2:5)]) 
icc(det[(det$n_raters==4), c(2:5)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==4), c(2:5)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(det[(det$n_raters==2), c(2:3)])$value * agree(det[(det$n_raters==2), c(2:3)])$subjects) +
  agree(det[(det$n_raters==3), c(2:4)])$value * agree(det[(det$n_raters==3), c(2:4)])$subjects +
  agree(det[(det$n_raters==4), c(2:5)])$value * agree(det[(det$n_raters==4), c(2:5)])$subjects 
  )/
  (agree(det[(det$n_raters==2), c(2:3)])$subjects
   + agree(det[(det$n_raters==3), c(2:4)])$subjects +
     agree(det[(det$n_raters==4), c(2:5)])$subjects 
   )

#LA----
#Two raters
agree(la[(la$n_raters==2), c(2:3)]) 
icc(la[(la$n_raters==2), c(2:3)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==2), c(2:3)])), "ordinal")

#Three raters
agree(la[(la$n_raters==3), c(2:4)]) 
icc(la[(la$n_raters==3), c(2:4)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==3), c(2:4)])), "ordinal")

#Four raters
agree(la[(la$n_raters==4), c(2:5)]) 
icc(la[(la$n_raters==4), c(2:5)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==4), c(2:5)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(la[(la$n_raters==2), c(2:3)])$value * agree(la[(la$n_raters==2), c(2:3)])$subjects) +
  agree(la[(la$n_raters==3), c(2:4)])$value * agree(la[(la$n_raters==3), c(2:4)])$subjects +
  agree(la[(la$n_raters==4), c(2:5)])$value * agree(la[(la$n_raters==4), c(2:5)])$subjects 
)/
  (agree(la[(la$n_raters==2), c(2:3)])$subjects
   + agree(la[(la$n_raters==3), c(2:4)])$subjects +
     agree(la[(la$n_raters==4), c(2:5)])$subjects 
  )


rm(bos,det,la) #Clean up environment
```

### Table 7: Reliability Between Raters and Predictions Panel 2

```{r single-reliability-betweenratersandmturk}
# Data----
#Look only at those that all agree in coding sessions

bos <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating"),pred_svm) %>% 
  filter(!is.na(pred_svm)) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(starts_with("single_cs_rating"))))) %>% 
  mutate(var = var(c_across(starts_with("single_cs_rating")), na.rm = TRUE)) %>% 
  filter(var==0 | (is.na(var) & !is.na(single_cs_rating1))) %>% #Keep those with no variance (i.e. equal) or NA variance (i.e. one rater)
  filter(city=="Boston") %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters))

det <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating"),pred_svm) %>% 
  filter(!is.na(pred_svm)) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(starts_with("single_cs_rating"))))) %>% 
  mutate(var = var(c_across(starts_with("single_cs_rating")), na.rm = TRUE)) %>% 
  filter(var==0 | (is.na(var) & !is.na(single_cs_rating1))) %>% #Keep those with no variance (i.e. equal) or NA variance (i.e. one rater)
  filter(city=="Detroit") %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters)) 

la <- single_image_cs %>% 
  dplyr::select(city,starts_with("single_cs_rating"),pred_svm) %>% 
  filter(!is.na(pred_svm)) %>% 
  rowwise() %>% 
  mutate(n_raters = sum(!is.na(c_across(starts_with("single_cs_rating"))))) %>% 
  mutate(var = var(c_across(starts_with("single_cs_rating")), na.rm = TRUE)) %>% 
  filter(var==0 | (is.na(var) & !is.na(single_cs_rating1))) %>% #Keep those with no variance (i.e. equal) or NA variance (i.e. one rater)
  filter(city=="LA") %>% 
  mutate(n_raters = ifelse(n_raters>4,4,n_raters))

# Boston----
#Two raters
agree(bos[(bos$n_raters==2), c(2:3,9)]) 
icc(bos[(bos$n_raters==2), c(2:3,9)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==2), c(2:3,9)])), "ordinal")

#Three raters
agree(bos[(bos$n_raters==3), c(2:4,9)]) 
icc(bos[(bos$n_raters==3), c(2:4,9)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==3), c(2:4,9)])), "ordinal")

#Four raters
agree(bos[(bos$n_raters==4), c(2:5,9)]) 
icc(bos[(bos$n_raters==4), c(2:5,9)], model = "twoway") 
kripp.alpha(t(as.matrix(bos[(bos$n_raters==4), c(2:5,9)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(bos[(bos$n_raters==2), c(2:3,9)])$value * agree(bos[(bos$n_raters==2), c(2:3,9)])$subjects) +
  agree(bos[(bos$n_raters==3), c(2:4,9)])$value * agree(bos[(bos$n_raters==3), c(2:4,9)])$subjects +
  agree(bos[(bos$n_raters==4), c(2:5,9)])$value * agree(bos[(bos$n_raters==4), c(2:5,9)])$subjects 
  )/
  (agree(bos[(bos$n_raters==2), c(2:3,9)])$subjects
   + agree(bos[(bos$n_raters==3), c(2:4,9)])$subjects +
     agree(bos[(bos$n_raters==4), c(2:5,9)])$subjects 
   )


# Detroit----
#Two raters
agree(det[(det$n_raters==2), c(2:3,9)]) 
icc(det[(det$n_raters==2), c(2:3,9)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==2), c(2:3,9)])), "ordinal")

#Three raters
agree(det[(det$n_raters==3), c(2:4,9)]) 
icc(det[(det$n_raters==3), c(2:4,9)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==3), c(2:4,9)])), "ordinal")

#Four raters
agree(det[(det$n_raters==4), c(2:5,9)]) 
icc(det[(det$n_raters==4), c(2:5,9)], model = "twoway") 
kripp.alpha(t(as.matrix(det[(det$n_raters==4), c(2:5,9)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(det[(det$n_raters==2), c(2:3,9)])$value * agree(det[(det$n_raters==2), c(2:3,9)])$subjects) +
  agree(det[(det$n_raters==3), c(2:4,9)])$value * agree(det[(det$n_raters==3), c(2:4,9)])$subjects +
  agree(det[(det$n_raters==4), c(2:5,9)])$value * agree(det[(det$n_raters==4), c(2:5,9)])$subjects 
)/
  (agree(det[(det$n_raters==2), c(2:3,9)])$subjects
   + agree(det[(det$n_raters==3), c(2:4,9)])$subjects +
     agree(det[(det$n_raters==4), c(2:5,9)])$subjects 
  )

#LA----

#Two raters
agree(la[(la$n_raters==2), c(2:3,9)]) 
icc(la[(la$n_raters==2), c(2:3,9)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==2), c(2:3,9)])), "ordinal")

#Three raters
agree(la[(la$n_raters==3), c(2:4,9)]) 
icc(la[(la$n_raters==3), c(2:4,9)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==3), c(2:4,9)])), "ordinal")

#Four raters
agree(la[(la$n_raters==4), c(2:5,9)]) 
icc(la[(la$n_raters==4), c(2:5,9)], model = "twoway") 
kripp.alpha(t(as.matrix(la[(la$n_raters==4), c(2:5,9)])), "ordinal")

#Overall - calculated weighted average of agreement
((agree(la[(la$n_raters==2), c(2:3,9)])$value * agree(la[(la$n_raters==2), c(2:3,9)])$subjects) +
  agree(la[(la$n_raters==3), c(2:4,9)])$value * agree(la[(la$n_raters==3), c(2:4,9)])$subjects +
  agree(la[(la$n_raters==4), c(2:5,9)])$value * agree(la[(la$n_raters==4), c(2:5,9)])$subjects 
)/
  (agree(la[(la$n_raters==2), c(2:3,9)])$subjects
   + agree(la[(la$n_raters==3), c(2:4,9)])$subjects +
     agree(la[(la$n_raters==4), c(2:5,9)])$subjects 
  )
```

## Trueskill v. Coding Session Figure
```{r fig-3}

# Aggregate Trueskill ratings
trueskill_agg <- single_image %>% 
  filter(!is.na(trueskill_rating)) %>% # Keep only those that have one Trueskill rating
  group_by(city,trueskill_rating) %>% 
  summarize(count = n()) %>% # Within each city-rating grouping, count how many there are
  mutate(perc = (count/sum(count))) %>% # Get percentage of each rating
  mutate(type = "Trueskill") %>% 
  rename(rating = trueskill_rating) # Rename to match other ratings

# Aggregate Trueskill ratings
cs_agg <- single_image %>% 
  dplyr::select(image_name,city,starts_with("single_cs_rating")) %>%
  filter(!is.na(single_cs_rating1)) %>% # Keep only those that have at least one coding session rating
  pivot_longer( # Reshape so that each coding session rating is its own row
    cols = starts_with("single_cs_rating"),
    values_to = "rating"
  ) %>% 
  filter(!is.na(rating) & !rating==0) %>% # Keep only those that don't have an obstructed rating
  group_by(city,rating) %>% 
  summarize(count = n()) %>% 
  mutate(perc = (count/sum(count))) %>% 
  mutate(type = "Coding Session") 

# Bind Trueskill and coding session ratings together
agg <- rbind(cs_agg,trueskill_agg)

# Get overall rates (not city disaggregated)
agg_overall <- agg %>% 
  group_by(type,rating) %>% 
  summarize(count = sum(count)) %>% 
  mutate(perc = (count/sum(count)))

#Plot each panel
#Overall----
agg_overall_plot <-
ggplot(agg_overall, aes(x=rating, y=perc,fill=type)) +
  geom_bar(position = "dodge", stat="identity") +
  geom_text(aes(label=count), position=position_dodge(width=0.9), vjust=-0.25) +
  scale_y_continuous(labels = scales::percent) + 
  coord_cartesian(ylim=c(0,0.80)) + 
  labs(title = "All Cities", y = "Percent", x="Rating", fill = "Rating Source") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("gray40", "gray70"))

#Boston----
agg_bos_plot <-
  agg %>% 
  filter(city == "Boston") %>% 
  ggplot(aes(x=rating, y=perc,fill=type)) +
  geom_bar(position = "dodge", stat="identity") +
  geom_text(aes(label=count), position=position_dodge(width=0.9), vjust=-0.25) +
  scale_y_continuous(labels = scales::percent) + 
  coord_cartesian(ylim=c(0,0.80)) + 
  labs(title = "Boston", y = "Percent", x="Rating", fill = "Rating Source") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("gray40", "gray70"))

#Detroit----
agg_det_plot <-
  agg %>% 
  filter(city == "Detroit") %>% 
  ggplot(aes(x=rating, y=perc,fill=type)) +
  geom_bar(position = "dodge", stat="identity") +
  geom_text(aes(label=count), position=position_dodge(width=0.9), vjust=-0.25) +
  scale_y_continuous(labels = scales::percent) + 
  coord_cartesian(ylim=c(0,0.80)) + 
  labs(title = "Detroit", y = "Percent", x="Rating", fill = "Rating Source") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("gray40", "gray70"))

#LA----
agg_la_plot <-
  agg %>% 
  filter(city == "LA") %>% 
  ggplot(aes(x=rating, y=perc,fill=type)) +
  geom_bar(position = "dodge", stat="identity") +
  geom_text(aes(label=count), position=position_dodge(width=0.9), vjust=-0.25) +
  scale_y_continuous(labels = scales::percent) + 
  coord_cartesian(ylim=c(0,0.80)) + 
  labs(title = "Los Angeles", y = "Percent", x="Rating", fill = "Rating Source") +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("gray40", "gray70"))

# Figure----
fig <- ggpubr::ggarrange(agg_overall_plot, agg_bos_plot, agg_det_plot, agg_la_plot,
                                        ncol = 2, nrow = 2,
                    common.legend = TRUE,
                    legend = "bottom")




```

## Coding Session v. Predictions Figure

```{r fig-4}
# Aggregate coding session ratings (binary)
cs_agg_binary <- single_image %>% 
  dplyr::select(image_name,city,starts_with("single_cs_rating")) %>% 
  filter(!is.na(single_cs_rating1)) %>% 
  pivot_longer(
    cols = starts_with("single_cs_rating"),
    values_to = "rating"
  ) %>% 
  filter(!is.na(rating) & !rating==0) %>% 
  mutate(rating = ifelse(rating > 1, 1, 0)) %>% 
  group_by(city,rating) %>% 
  summarize(count = n()) %>% 
  mutate(perc = (count/sum(count))) %>% 
  mutate(type = "Coding Session") %>% 
  mutate(rating = factor(rating,
                         labels = c("No Trash", "Trash"))) %>% 
  mutate(rating = relevel(rating, ref = "No Trash"))

# Aggregate predictions
preds_agg <- single_image %>% 
  filter(!is.na(pred_svm)) %>% # Keep only those with a prediction
  group_by(city,pred_svm) %>% 
  summarize(count = n()) %>% 
  mutate(perc = (count/sum(count))) %>% 
  mutate(type = "ML") %>% 
  rename(rating = pred_svm) %>% 
  mutate(rating = factor(rating,
                         labels = c("No Trash", "Trash"))) %>% 
  mutate(rating = relevel(rating, ref = "No Trash"))

# Bind predictions and coding sessions together
agg <- rbind(preds_agg,cs_agg_binary)

# Get overall rates (not city disaggregated)
agg_overall <- agg %>% 
  group_by(type,rating) %>% 
  summarize(count = sum(count)) %>% 
  mutate(perc = (count/sum(count)))

#Plot each panel

#Overall----
agg_overall_plot <-
ggplot(agg_overall, aes(x=type, y=perc,fill=rating)) +
  geom_bar(position = "stack", stat="identity") +
  scale_y_continuous(labels = scales::percent) + 
  labs(title = "All Cities", y = "Percent", x="Rating Source", fill = "Rating") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("gray40", "gray70"))

#Boston----
agg_bos_plot <-
  agg %>% 
  filter(city == "Boston") %>% 
  ggplot(aes(x=type, y=perc,fill=rating)) +
  geom_bar(position = "stack", stat="identity") +
  scale_y_continuous(labels = scales::percent) + 
  labs(title = "Boston", y = "Percent", x="Rating Source", fill = "Rating") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("gray40", "gray70"))

#Detroit----
agg_det_plot <-
  agg %>% 
  filter(city == "Detroit") %>% 
   ggplot(aes(x=type, y=perc,fill=rating)) +
  geom_bar(position = "stack", stat="identity") +
  scale_y_continuous(labels = scales::percent) + 
  labs(title = "Detroit", y = "Percent", x="Rating Source", fill = "Rating") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("gray40", "gray70"))

#LA----
agg_la_plot <-
  agg %>% 
  filter(city == "LA") %>% 
  ggplot(aes(x=type, y=perc,fill=rating)) +
  geom_bar(position = "stack", stat="identity") +
  scale_y_continuous(labels = scales::percent) + 
  labs(title = "Los Angeles", y = "Percent", x="Rating Source", fill = "Rating") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("gray40", "gray70"))

#Figure----
fig <- ggpubr::ggarrange(agg_overall_plot, agg_bos_plot, agg_det_plot, agg_la_plot,
                                        ncol = 2, nrow = 2,
                    common.legend = TRUE,
                    legend = "bottom") 


```