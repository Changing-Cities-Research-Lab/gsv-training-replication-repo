{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import util\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage #require scikit-image pkg\n",
    "import sys\n",
    "import torchvision.models as models\n",
    "import pickle as pickle\n",
    "import urllib.request\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torch import topk\n",
    "from PIL import Image\n",
    "from img2vec import img_to_vec\n",
    "from torch.nn import functional as F\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, r2_score\n",
    "from docopt import docopt\n",
    "from pprint import pprint\n",
    "from os import walk\n",
    "from sklearn.manifold import TSNE\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "from skimage import io as skio\n",
    "import io\n",
    "\n",
    "from svm_classifier import predict_test\n",
    "from test_model import *\n",
    "from constants import * \n",
    "from util import get_splits_csv, get_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_components(df):\n",
    "    \"\"\"\n",
    "    Takes as input a dataframe containing image name, column of string features, and true rating.\n",
    "    Outputs original dataframe with additional columns for the first four PCA components as well as two TSNE components\n",
    "    \"\"\"\n",
    "    feature_array = features_to_array(pd.DataFrame(df.features))\n",
    "    pca = PCA(n_components=4)\n",
    "    pca_result = pca.fit_transform(feature_array)\n",
    "    pca_df = pd.DataFrame()\n",
    "    pca_df['pca-one'] = pca_result[:,0]\n",
    "    pca_df['pca-two'] = pca_result[:,1] \n",
    "    pca_df['pca-three'] = pca_result[:,2]\n",
    "    pca_df['pca-four'] = pca_result[:,3]\n",
    "    pca_df['image_name'] = df.image_name\n",
    "    pca_df['rating'] = df.rating\n",
    "    pca_df['features'] = df.features\n",
    "\n",
    "    print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(feature_array)\n",
    "    len(tsne_results)\n",
    "    pca_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "    pca_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "    return(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_similarity(df, df2):\n",
    "    \"\"\"\n",
    "    Given a dataframe (with features column) and another dataframe.\n",
    "    Outputs a column of length of dataframe with float values for cosine similarities between target image \n",
    "    and every other image in dataframe.\n",
    "    \"\"\"\n",
    "    #target_features = features_to_array(pd.DataFrame(df.loc[(df.image_name == target_image)].features))\n",
    "    target_features = features_to_array(pd.DataFrame(df2.features))\n",
    "    feature_array = features_to_array(pd.DataFrame(df.features))\n",
    "    similarities = cosine_similarity(feature_array, target_features)\n",
    "    print(similarities.shape)\n",
    "    return similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_for_feature(df, feature, direction, n=10):\n",
    "    \"\"\"\n",
    "    Given dataframe with image names, the name of a column in the dataframe, and a direction (True for ascending,\n",
    "    False for descending). Dataframe must have a column for the S3 url of the image.\n",
    "    Returns an image grid of images with the highest (or lowest) values along the given axis.\n",
    "    \"\"\"\n",
    "    image_sample = df.sort_values(by = feature, ascending=direction)[:n]\n",
    "    image_datas = image_sample.url\n",
    "\n",
    "    fig=plt.figure(figsize=(20, n*3))\n",
    "    columns = 2\n",
    "    rows = int(n/2)\n",
    "    for i, imagerow in enumerate(image_datas):\n",
    "        img = skio.imread(imagerow)\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        plt.title(imagerow)\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(image_csv_path, output_name, num_output_labels, model_name, url_path, quiet=False):\n",
    "    \"\"\"\n",
    "    Extracts convolutional image features given dataframe of images [image_csv_path], trained resnet model [model_name], \n",
    "    and number of output labels, as well as url path for images. \n",
    "    Returns data and writes all data to desired location [output_name]\n",
    "    \"\"\"\n",
    "    print(model_name)\n",
    "    if model_name:\n",
    "        img_2_vec = img_to_vec.Img2Vec(model=model_name, num_output_labels=num_output_labels)\n",
    "    else:\n",
    "        img_2_vec = img_to_vec.Img2Vec(num_output_labels=num_output_labels)\n",
    "    # csv file image_name, trueskill_score\n",
    "    data = pd.read_csv(image_csv_path)\n",
    "    print(data.columns)\n",
    "    data['pred_resnet'] = ''\n",
    "    data['features'] = ''\n",
    "\n",
    "    def get_image_features(row):\n",
    "        try:\n",
    "            if not quiet:  # for some reason, apply runs the first row twice\n",
    "                print(' EXTRACTING IMAGE FEATURES:', row.image_name)\n",
    "            URL = url_path + row.image_name\n",
    "\n",
    "            with urllib.request.urlopen(URL) as url:\n",
    "                f = io.BytesIO(url.read())\n",
    "\n",
    "            img = Image.open(f)\n",
    "            \n",
    "            vec = img_2_vec.get_vec(img)\n",
    "            pred = img_2_vec.predict_image(img)\n",
    "            row.features = json.dumps(vec.tolist())\n",
    "            row.pred_resnet = json.dumps(pred.tolist())\n",
    "#            print(row)\n",
    "            return row\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    print('extracting features for {} ({} images) using {}'.format(image_csv_path, len(data), model_name))\n",
    "\n",
    "    data = data.apply(get_image_features, axis=1)\n",
    "    data.to_csv(output_name, index=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url_path = 'WHERE IMAGES ARE STORED'\n",
    "# This should be a URL or directory that points to where images are saved.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate PCA components for images with discrepancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrepancies_features = extract_image_features(\n",
    "'PATH TO CSV WITH IMAGES WITH DISCREPANCIES',\n",
    "'PATH TO OUTPUT CSV NAME',\n",
    "2, # NUMBER OF OUTPUT LABELS\n",
    "'PATH TO TRAINED RESNET MODEL',\n",
    "image_url_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = extract_image_features(\n",
    "'PATH TO CSV WITH FULL SET OF IMAGES',\n",
    "'PATH TO OUTPUT CSV NAME',\n",
    "2, # NUMBER OF OUTPUT LABELS\n",
    "'PATH TO TRAINED RESNET MODEL',\n",
    "image_url_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svm_classifier import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "pca_df = get_components(discrepancies_features.dropna()).dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate similarity between all images and images with discrepancies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_df = pd.read_csv('PATH TO DISCREPANCIES FEATURES')\n",
    "\n",
    "full_df = pd.read_csv('PATH TO ALL IMAGES FEATURES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = get_feature_similarity(dis_df,full_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
